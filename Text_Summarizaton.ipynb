{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOcsqoCcxPzPdG7i+HDoX2m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tadeoaguilar/Generative_AI_Apps/blob/main/Text_Summarizaton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4Av8X1eXNCL",
        "outputId": "60538046-85b2-4a82-b76b-63afc5a39257"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: pydantic-ai 1.37.0 does not provide the extra 'logfire'\u001b[0m\u001b[33m\n",
            "\u001b[0m✓ Installation complete!\n"
          ]
        }
      ],
      "source": [
        "# @title Install Dependencies (run once per session)\n",
        "!pip install -q datasets>=3.1.0 ipykernel>=6.29.5 langchain-chroma>=0.1.4 \\\n",
        "    langchain-huggingface>=0.1.2 langchain-openai>=0.2.9 langchain>=0.3.7 \\\n",
        "    python-dotenv>=1.0.1 wikipedia>=1.4.0 ag2>=0.3.2 nltk>=3.9.1 \\\n",
        "    langgraph>=0.2.56 langchain-groq>=0.2.1 agentops>=0.3.21 \\\n",
        "    \"pydantic-ai[logfire]>=0.0.15\" nest-asyncio>=1.6.0 \\\n",
        "    langchain-community>=0.3.7 uvicorn>=0.32.1 ragas>=0.2.11 \\\n",
        "    accelerate>=1.3.0 openai-agents>=0.0.7 langchain-community>=0.3.7 pymupdf\\\n",
        "\n",
        "\n",
        "print(\"✓ Installation complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%% packages\n",
        "from transformers import pipeline\n",
        "from langchain_community.document_loaders import ArxivLoader"
      ],
      "metadata": {
        "id": "NmyqMDrRdzIp"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lkTGgSDGdyag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%% model selection\n",
        "task = \"summarization\"\n",
        "model = \"sshleifer/distilbart-cnn-12-6\"\n",
        "summarizer = pipeline(task= task, model=model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbVOV89PbE-W",
        "outputId": "d3ad85c7-d275-4cc0-a77c-957a17c15c58"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%% Data Preparation\n",
        "query = \"prompt engineering\"\n",
        "loader = ArxivLoader(query=query, load_max_docs=1)\n",
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "-GjQWoUgbvdX"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %% Data Preparation\n",
        "article_text = docs[0].page_content"
      ],
      "metadata": {
        "id": "saOtVMDPeWmw"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "result = summarizer(article_text[:2000], min_length=20, max_length=80, do_sample=False)\n",
        "result[0]['summary_text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "qiwwChs6ecF4",
        "outputId": "1d960209-71ae-4b94-a34a-5d8e0d456fae"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Towards Goal-oriented Prompt Engineering for Large Language Models: A Survey. A Survey by Nanyang Technological University, Singapore. The paper aims to highlight the limitation of designing prompts that expect LLMs to think like humans.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(result[0]['summary_text'].split(' '))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gl7Za-6Oelft",
        "outputId": "2cee6122-57be-4c01-cd87-0176db38378f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    }
  ]
}